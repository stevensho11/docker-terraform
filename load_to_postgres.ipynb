{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4cc65e0-46af-43d5-a1b4-061e809a3e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0da188de-e309-4cb4-9ef7-c28012601fe1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c8fd5b9-77c4-4064-8aec-29bd5d8fad8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('yellow_tripdata_2025-01')\n",
    "df.to_csv('yellow_trip_data_2025-01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "abcbc910-f907-47fc-818f-9283c4e6b180",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv = pd.read_csv('yellow_trip_data_2025-01', nrows=100, index_col=0)\n",
    "df_csv.head(5)\n",
    "df_csv.tpep_pickup_datetime = pd.to_datetime(df_csv.tpep_pickup_datetime)\n",
    "df_csv.tpep_dropoff_datetime = pd.to_datetime(df_csv.tpep_dropoff_datetime)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4614747b-8a14-421d-82ef-9afc42be28fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('postgresql://root:root@localhost:5432/ny_taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1c72c1e3-8791-4548-a2c8-0dc429103341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE yellow_taxi_data (\n",
      "\t\"VendorID\" BIGINT, \n",
      "\ttpep_pickup_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\ttpep_dropoff_datetime TIMESTAMP WITHOUT TIME ZONE, \n",
      "\tpassenger_count FLOAT(53), \n",
      "\ttrip_distance FLOAT(53), \n",
      "\t\"RatecodeID\" FLOAT(53), \n",
      "\tstore_and_fwd_flag TEXT, \n",
      "\t\"PULocationID\" BIGINT, \n",
      "\t\"DOLocationID\" BIGINT, \n",
      "\tpayment_type BIGINT, \n",
      "\tfare_amount FLOAT(53), \n",
      "\textra FLOAT(53), \n",
      "\tmta_tax FLOAT(53), \n",
      "\ttip_amount FLOAT(53), \n",
      "\ttolls_amount FLOAT(53), \n",
      "\timprovement_surcharge FLOAT(53), \n",
      "\ttotal_amount FLOAT(53), \n",
      "\tcongestion_surcharge FLOAT(53), \n",
      "\t\"Airport_fee\" FLOAT(53), \n",
      "\tcbd_congestion_fee FLOAT(53)\n",
      ")\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.io.sql.get_schema(df_csv, name='yellow_taxi_data', con=engine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "27c28679-810d-4c83-8346-02fe26ee641e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv_iter = pd.read_csv('yellow_trip_data_2025-01', index_col=0, iterator=True, chunksize=100000)\n",
    "df_csv = next(df_csv_iter)\n",
    "len(df_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "fc60f02a-3096-42f4-b4fc-f9d17d0476b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_csv.tpep_pickup_datetime = pd.to_datetime(df_csv.tpep_pickup_datetime)\n",
    "df_csv.tpep_dropoff_datetime = pd.to_datetime(df_csv.tpep_dropoff_datetime)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "63abc60b-1c41-4625-a9e4-6013eef7b1ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_csv.head(n=0).to_sql(name='yellow_taxi_data', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bfe8ed63-4347-4c64-b14e-eb075d0b9180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.23 s, sys: 105 ms, total: 3.33 s\n",
      "Wall time: 5.36 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time df_csv.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2fde6237-2f94-46a5-b769-57de6920f3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted chunl... took 5.508 second\n",
      "inserted chunl... took 5.463 second\n",
      "inserted chunl... took 5.542 second\n",
      "inserted chunl... took 5.618 second\n",
      "inserted chunl... took 5.521 second\n",
      "inserted chunl... took 5.317 second\n",
      "inserted chunl... took 5.443 second\n",
      "inserted chunl... took 5.453 second\n",
      "inserted chunl... took 5.410 second\n",
      "inserted chunl... took 5.369 second\n",
      "inserted chunl... took 5.321 second\n",
      "inserted chunl... took 5.469 second\n",
      "inserted chunl... took 5.588 second\n",
      "inserted chunl... took 5.864 second\n",
      "inserted chunl... took 5.403 second\n",
      "inserted chunl... took 5.451 second\n",
      "inserted chunl... took 5.390 second\n",
      "inserted chunl... took 5.367 second\n",
      "inserted chunl... took 5.466 second\n",
      "inserted chunl... took 5.400 second\n",
      "inserted chunl... took 5.531 second\n",
      "inserted chunl... took 5.234 second\n",
      "inserted chunl... took 5.465 second\n",
      "inserted chunl... took 5.519 second\n",
      "inserted chunl... took 5.406 second\n",
      "inserted chunl... took 5.570 second\n",
      "inserted chunl... took 5.261 second\n",
      "inserted chunl... took 5.391 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/pyqd0js165q002h2tdsq4g4c0000gn/T/ipykernel_43344/3432102154.py:5: DtypeWarning: Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_csv = next(df_csv_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inserted chunl... took 5.106 second\n",
      "inserted chunl... took 5.088 second\n",
      "inserted chunl... took 4.941 second\n",
      "inserted chunl... took 5.058 second\n",
      "inserted chunl... took 4.986 second\n",
      "inserted chunl... took 3.763 second\n"
     ]
    },
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[84]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      4\u001b[39m     t_start = time()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     df_csv = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_csv_iter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     df_csv.tpep_pickup_datetime = pd.to_datetime(df_csv.tpep_pickup_datetime)\n\u001b[32m      8\u001b[39m     df_csv.tpep_dropoff_datetime = pd.to_datetime(df_csv.tpep_dropoff_datetime)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/docker-terraform/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1843\u001b[39m, in \u001b[36mTextFileReader.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1841\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> DataFrame:\n\u001b[32m   1842\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1843\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1844\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[32m   1845\u001b[39m         \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/docker-terraform/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1985\u001b[39m, in \u001b[36mTextFileReader.get_chunk\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m   1983\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m   1984\u001b[39m     size = \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m.nrows - \u001b[38;5;28mself\u001b[39m._currow)\n\u001b[32m-> \u001b[39m\u001b[32m1985\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/docker-terraform/venv/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1923\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1916\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1917\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1918\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1919\u001b[39m     (\n\u001b[32m   1920\u001b[39m         index,\n\u001b[32m   1921\u001b[39m         columns,\n\u001b[32m   1922\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1923\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1925\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1926\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1927\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/projects/docker-terraform/venv/lib/python3.13/site-packages/pandas/io/parsers/c_parser_wrapper.py:234\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    235\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    236\u001b[39m         data = _concatenate_chunks(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mparsers.pyx:863\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mStopIteration\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "while True:\n",
    "    t_start = time()\n",
    "    df_csv = next(df_csv_iter)\n",
    "\n",
    "    df_csv.tpep_pickup_datetime = pd.to_datetime(df_csv.tpep_pickup_datetime)\n",
    "    df_csv.tpep_dropoff_datetime = pd.to_datetime(df_csv.tpep_dropoff_datetime)\n",
    "\n",
    "    df_csv.to_sql(name='yellow_taxi_data', con=engine, if_exists='append')\n",
    "\n",
    "    t_end = time()\n",
    "\n",
    "    print('inserted chunl... took %.3f second' % (t_end - t_start))\n",
    "    # print(f\"inserted chunk... took {(t_end - t_start):.3f} second\")\n",
    "    # print(\"inserted chunk... took {:.3f} second\".format(t_end - t_start))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6092d15d-07ea-4121-81a7-f20b12ca29bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
